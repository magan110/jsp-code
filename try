# ask_gemini.py
# Natural-language Q&A over a local Parquet export (db_export_bwlive / do_export_bwlive)
# Requires: pip install google-generativeai duckdb pandas pyarrow

import os
import re
import sys
import json
import argparse
from typing import Dict, List, Tuple

import duckdb
import pandas as pd

# --- Gemini SDK ---
try:
    import google.generativeai as genai
except Exception:
    print("Missing dependency: google-generativeai. Install with:\n  pip install google-generativeai")
    sys.exit(1)

# ---------------- CONFIG (overridable via CLI/env) ----------------
EXPORT_CANDIDATES = ["db_export_bwlive", "do_export_bwlive"]  # we’ll accept either name
MODEL_NAME = os.environ.get("GEMINI_MODEL", "gemini-1.5-flash")

MAX_TABLES_TO_TRY = int(os.environ.get("AG_MAX_TABLES", "200"))
PROBE_ROWS = int(os.environ.get("AG_PROBE_ROWS", "250"))
ROWS_PER_TABLE_TO_CONTEXT = int(os.environ.get("AG_ROWS_PER_TABLE", "6"))
MAX_CONTEXT_CHARS = int(os.environ.get("AG_MAX_CONTEXT_CHARS", "12000"))
# ------------------------------------------------------------------


# --------------- Path + catalog helpers ---------------
def locate_export_root(cli_arg: str | None = None) -> str:
    """
    Find the export root (folder that contains 'parquet/' and optionally catalog.json).
    Priority: CLI arg → env vars → next to script → parent of script → CWD.
    """
    if cli_arg and os.path.isdir(cli_arg):
        return os.path.abspath(cli_arg)

    for env in ("EXPORT_ROOT", "BWLIVE_EXPORT", "DB_EXPORT_ROOT"):
        p = os.environ.get(env)
        if p and os.path.isdir(p):
            return os.path.abspath(p)

    here = os.path.dirname(os.path.abspath(__file__))
    candidates = []
    # next to the script
    candidates += [os.path.join(here, name) for name in EXPORT_CANDIDATES]
    # parent of the script
    candidates += [os.path.join(here, "..", name) for name in EXPORT_CANDIDATES]
    # current working dir
    candidates += [os.path.join(os.getcwd(), name) for name in EXPORT_CANDIDATES]

    for p in candidates:
        if os.path.isdir(p):
            return os.path.abspath(p)

    raise SystemExit(
        "Export folder not found.\n"
        f"Provide it with -e/--export, set EXPORT_ROOT, or create one of: {', '.join(EXPORT_CANDIDATES)} "
        "next to this script (containing a 'parquet' subfolder)."
    )

def cat_path(root: str) -> str:
    return os.path.join(root, "catalog.json")

def ensure_catalog(root: str) -> Dict:
    """
    Load catalog.json or build it by scanning export_root/parquet/<schema>/*.parquet
    """
    cpath = cat_path(root)
    if os.path.isfile(cpath):
        with open(cpath, "r", encoding="utf-8") as f:
            return json.load(f)

    parquet_dir = os.path.join(root, "parquet")
    if not os.path.isdir(parquet_dir):
        raise SystemExit(f"Parquet directory not found: {parquet_dir}")

    db_name = os.path.basename(root).replace("db_export_", "")
    cat = {"database": db_name, "export_root": os.path.abspath(root), "tables": {}}

    for schema in sorted(os.listdir(parquet_dir)):
        sp = os.path.join(parquet_dir, schema)
        if not os.path.isdir(sp):
            continue
        for fn in sorted(os.listdir(sp)):
            if fn.lower().endswith(".parquet"):
                table = fn[:-8]
                key = f"{schema}.{table}"
                cat["tables"][key] = {
                    "schema": schema,
                    "table": table,
                    "parquet": os.path.join(sp, fn),
                }

    with open(cpath, "w", encoding="utf-8") as f:
        json.dump(cat, f, indent=2)
    return cat

def list_tables(cat: Dict) -> List[str]:
    return sorted([f"{v['schema']}.{v['table']}" for v in cat["tables"].values()], key=str.lower)

def _norm_path(p: str) -> str:
    return p.replace("\\", "/")

def _sql_escape_like(s: str) -> str:
    return (s or "").replace("'", "''")
# ------------------------------------------------------


# --------------- Table probing + retrieval ---------------
def _detect_string_cols(con: duckdb.DuckDBPyConnection, parquet_path: str) -> List[str]:
    try:
        df = con.execute(
            f"SELECT * FROM parquet('{_sql_escape_like(_norm_path(parquet_path))}') LIMIT {PROBE_ROWS}"
        ).fetchdf()
    except Exception:
        return []
    return [c for c in df.columns if str(df[c].dtype) in ("object", "string", "category")]

def _search_tokens(
    con: duckdb.DuckDBPyConnection,
    parquet_path: str,
    tokens: List[str],
    strcols: List[str],
) -> pd.DataFrame:
    if not strcols or not tokens:
        return pd.DataFrame()
    # AND across tokens; for each token, OR across columns
    parts = []
    for t in tokens:
        t_esc = _sql_escape_like(t)
        ors = [f"CAST(\"{c}\" AS VARCHAR) ILIKE '%{t_esc}%'" for c in strcols]
        parts.append("(" + " OR ".join(ors) + ")")
    where = " AND ".join(parts)
    q = (
        f"SELECT * FROM parquet('{_sql_escape_like(_norm_path(parquet_path))}') "
        f"WHERE {where} LIMIT {ROWS_PER_TABLE_TO_CONTEXT}"
    )
    try:
        return con.execute(q).fetchdf()
    except Exception:
        return pd.DataFrame()
# --------------------------------------------------------


# --------------- Query parsing helpers ---------------
def _extract_tokens(q: str) -> List[str]:
    # if quoted text exists, prefer those tokens
    m = re.search(r"[\"“”‘’']([^\"“”‘’']+)[\"“”‘’']", q)
    if m:
        raw = re.findall(r"[A-Za-z0-9@+._/-]+", m.group(1))
        return [t for t in raw if t]

    raw = re.findall(r"[A-Za-z0-9@+._/-]+", q)
    stop = {
        "what", "is", "are", "the", "a", "an", "of", "for", "about",
        "list", "show", "name", "names", "tables", "table", "please"
    }
    toks = [t for t in raw if (t.lower() not in stop) and (any(c.isdigit() for c in t) or len(t) >= 3)]
    return toks or (raw[-1:] if raw else [])

def meta_list_tables(q: str) -> bool:
    L = q.lower().strip()
    return (
        (("list" in L or "show" in L or "name" in L) and "table" in L)
        or L in {"tables", "list tables", "show tables", "name of all tables"}
    )

def meta_topn(q: str):
    m = re.search(r"\btop\s+(\d+)\s+([A-Za-z0-9_.-]+)", q, flags=re.IGNORECASE)
    if m:
        return int(m.group(1)), m.group(2)
    return None

def best_table(catalog: Dict, frag: str) -> Tuple[str, Dict, int]:
    frag = frag.lower()
    best_key, best_meta, best_score = None, None, -1
    for key, meta in catalog["tables"].items():
        cands = [key.lower(), meta["table"].lower(), f"{meta['schema'].lower()}.{meta['table'].lower()}"]
        score = max(int(frag in c) * 100 + len(os.path.commonprefix([frag, c])) for c in cands)
        if score > best_score:
            best_key, best_meta, best_score = key, meta, score
    return best_key, best_meta, best_score
# -----------------------------------------------------


# --------------- Context builder for Gemini ---------------
def build_context(cat: Dict, question: str) -> str:
    con = duckdb.connect(database=":memory:")
    tokens = _extract_tokens(question)
    chunks: List[str] = []
    total_len = 0

    for key, meta in list(cat["tables"].items())[:MAX_TABLES_TO_TRY]:
        p = meta["parquet"]
        strcols = _detect_string_cols(con, p)
        if not strcols:
            continue
        hits = _search_tokens(con, p, tokens, strcols)
        if hits.empty:
            continue

        block = f"TABLE {meta['schema']}.{meta['table']} (columns: {', '.join(hits.columns.tolist())}):\n"
        block += hits.to_string(index=False)
        block += "\n\n"
        if total_len + len(block) > MAX_CONTEXT_CHARS:
            break
        chunks.append(block)
        total_len += len(block)

    con.close()

    if not chunks:
        # fall back to schema-only view to let Gemini at least guide the user
        names = list_tables(cat)
        return "TABLES AVAILABLE:\n" + ", ".join(names) + "\n"
    return "".join(chunks)
# ---------------------------------------------------------


# --------------- Gemini call ---------------
def gemini_answer(question: str, context: str, model_name: str) -> str:
    api_key = os.environ.get("GEMINI_API_KEY", "")
    if not api_key:
        raise SystemExit("Set GEMINI_API_KEY environment variable first (from Google AI Studio).")
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(model_name)

    prompt = (
        "You are a careful data assistant working over a database export.\n"
        "Use ONLY the database context below. If the answer is not present, reply exactly: Not found.\n\n"
        f"User question:\n{question}\n\n"
        f"Database context (snippets):\n{context}\n\n"
        "Respond concisely with the value(s) found. If multiple plausible matches exist, "
        "return the best one or a short comma-separated list. Do not invent columns or values."
    )

    try:
        resp = model.generate_content(prompt)
        text = (resp.text or "").strip()
    except Exception as e:
        text = f"Error calling Gemini: {e}"
    return text
# ------------------------------------------


# --------------- Main answer flow ---------------
def answer(root: str, q: str, model_name: str):
    cat = ensure_catalog(root)

    if meta_list_tables(q):
        print(", ".join(list_tables(cat)))
        return

    topn = meta_topn(q)
    if topn:
        n, frag = topn
        key, meta, score = best_table(cat, frag)
        if not meta or score < 10:
            print("Not found")
            return
        con = duckdb.connect(database=":memory:")
        p = _norm_path(meta["parquet"])
        try:
            df = con.execute(f"SELECT * FROM parquet('{_sql_escape_like(p)}') LIMIT {n}").fetchdf()
            print(df.to_string(index=False) if not df.empty else "Not found")
        except Exception:
            print("Not found")
        finally:
            con.close()
        return

    ctx = build_context(cat, q)
    ans = gemini_answer(q, ctx, model_name)
    print(ans if ans else "Not found")
# ------------------------------------------------


# --------------- CLI ---------------
def main():
    ap = argparse.ArgumentParser(description="Gemini-powered NL Q&A over local Parquet export")
    ap.add_argument("-e", "--export", help="Path to export root (folder containing 'parquet/')", default=None)
    ap.add_argument("-m", "--model", help="Gemini model name (default from GEMINI_MODEL env or gemini-1.5-flash)", default=None)
    ap.add_argument("question", nargs="*", help="Your natural-language question")
    args = ap.parse_args()

    root = locate_export_root(args.export)
    model_name = args.model or MODEL_NAME

    if args.question:
        q = " ".join(args.question).strip()
        answer(root, q, model_name)
        return

    # Interactive mode
    print("Gemini DB Q&A over Parquet")
    print(f"Export root: {root}")
    print("Examples:")
    print('  name of all tables')
    print('  phone number of "rajendra shikwal"')
    print('  customer code of PZ6115')
    print('  top 5 adtAnnGifts')
    print("Type 'exit' to quit.")
    while True:
        try:
            q = input("\n> ").strip()
        except (EOFError, KeyboardInterrupt):
            break
        if not q or q.lower() in {"exit", "quit"}:
            break
        answer(root, q, model_name)


if __name__ == "__main__":
    main()
