import re
import os
import sys
import json
import urllib.parse
from collections import defaultdict
from typing import List, Dict, Tuple

import pandas as pd
from sqlalchemy import create_engine, inspect, text
from rapidfuzz import fuzz, process

# ─── DB CONFIG (use your values) ─────────────────────────────────────────────
SERVER   = "10.4.64.15"
DATABASE = "bwlive"
USER     = "birlawhite"
PASSWORD = "M@nsv1530"
ODBC_DRIVER = "ODBC Driver 17 for SQL Server"  # or "ODBC Driver 18 for SQL Server"
# ─────────────────────────────────────────────────────────────────────────────

# Optional: where a pre-dumped schema.json exists (from your previous script).
# If not present, we’ll read INFORMATION_SCHEMA live.
SCHEMA_JSON = os.path.join(f"db_schema_{DATABASE}", "schema.json")

# Search limits to keep things fast/safe
MAX_TABLES_TO_QUERY = 25
ROWS_PER_QUERY = 10

# Heuristic dictionaries (add as you like)
SYNONYMS = {
    "phone": ["phone", "mobile", "mob", "contact", "tel", "telephone", "cell", "phno", "ph", "contactno", "mobile_no", "mobileNo"],
    "email": ["email", "mail", "e-mail", "emailid", "email_id"],
    "name":  ["name", "fullname", "first", "last", "employee", "empname", "contactname", "person", "custname", "customername", "vendorname", "retailer", "party"],
    "id":    ["id", "empid", "employeeid", "poornata_id", "customerid", "vendorid", "code", "custcode", "retlcode"],
    "address": ["address", "addr", "street", "location"],
    "dept":  ["department", "dept"],
    "manager": ["manager", "reporting", "rpt_to", "report_to", "reportsto"],
}

# Column type hints (if schema.json contains types, we use them)
TEXT_TYPES_HINT = ("char", "text", "nchar", "varchar", "nvarchar")

# ─── Utilities ───────────────────────────────────────────────────────────────

def make_engine():
    params = urllib.parse.quote_plus(
        f"Driver={{{ODBC_DRIVER}}};"
        f"Server={SERVER};"
        f"Database={DATABASE};"
        f"UID={USER};"
        f"PWD={PASSWORD};"
        f"TrustServerCertificate=Yes;"
        f"Encrypt=no;"
    )
    return create_engine(f"mssql+pyodbc:///?odbc_connect={params}")

def load_schema(engine) -> List[Dict]:
    """
    Returns list of dicts: {schema, table, column, type, nullable, default}
    Prefer local schema.json if present; else use INFORMATION_SCHEMA.
    """
    if os.path.exists(SCHEMA_JSON):
        with open(SCHEMA_JSON, "r", encoding="utf-8") as f:
            return json.load(f)

    # Fallback: query INFORMATION_SCHEMA live
    q = text("""
        SELECT
            TABLE_SCHEMA AS [schema],
            TABLE_NAME   AS [table],
            COLUMN_NAME  AS [column],
            DATA_TYPE    AS [type]
        FROM INFORMATION_SCHEMA.COLUMNS
        ORDER BY TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION
    """)
    with engine.connect() as conn:
        df = pd.read_sql(q, conn)
    df["nullable"] = True
    df["default"] = ""
    return df.to_dict(orient="records")

def tokenize(q: str) -> List[str]:
    return re.findall(r"[A-Za-z0-9_]+", q.lower())

def best_match_columns(schema_rows: List[Dict], label_list: List[str]) -> Dict[str, List[Tuple[str, str, str, int]]]:
    """
    For each synonym label group, find columns whose names fuzzy-match any synonym.
    Returns: label -> list of (schema, table, column, score)
    """
    results = defaultdict(list)
    for row in schema_rows:
        col = row["column"].lower()
        stc = f"{row['schema']}.{row['table']}.{row['column']}".lower()
        for label in label_list:
            synonyms = SYNONYMS.get(label, [])
            # direct hit first
            for syn in synonyms:
                score = fuzz.partial_ratio(col, syn.lower())
                if score >= 75:
                    results[label].append((row["schema"], row["table"], row["column"], score))
                    break
    # Dedup per label keeping highest score per column
    dedupd = {}
    for label, items in results.items():
        keyd = {}
        for s, t, c, sc in items:
            key = (s, t, c)
            if key not in keyd or sc > keyd[key]:
                keyd[key] = sc
        dedupd[label] = sorted([(s, t, c, sc) for (s, t, c), sc in keyd.items()],
                               key=lambda x: x[3], reverse=True)
    return dedupd

def extract_entity(nlq: str) -> str:
    """
    Simple heuristic: words after ' of ' or quoted text become the entity.
    e.g., "Phone number of rajendra shikwal" -> "rajendra shikwal"
    """
    m = re.search(r"\bof\s+(.+)$", nlq.strip(), flags=re.IGNORECASE)
    if m:
        ent = m.group(1).strip().strip("?")
        return ent.strip("'\" ")
    # quoted
    m2 = re.search(r"[\"']([^\"']+)[\"']", nlq)
    if m2:
        return m2.group(1).strip()
    # fallback: take last 2-4 tokens that look like a name
    toks = tokenize(nlq)
    common = set(sum(SYNONYMS.values(), []))
    candidates = [t for t in toks if t not in common and not t.isdigit()]
    return " ".join(candidates[-3:]) if candidates else nlq

def guess_intent(nlq: str) -> Dict:
    """
    Classify which attribute user wants (phone/email/address/etc.)
    """
    L = nlq.lower()
    for label, words in SYNONYMS.items():
        for w in words:
            if re.search(rf"\b{re.escape(w)}\b", L):
                return {"want": label}
    # default: name lookup
    return {"want": "name"}

def build_candidates(schema_rows: List[Dict], want_label: str) -> List[Dict]:
    """
    Choose tables that have BOTH:
      - a column matching the 'want' (e.g., phone)
      - and a 'name-like' column to search by entity
    """
    by_table = defaultdict(lambda: {"want_cols": [], "name_cols": [], "text_cols": []})
    for r in schema_rows:
        s, t, c, typ = r["schema"], r["table"], r["column"], str(r["type"]).lower()
        key = (s, t)
        if any(k in c.lower() for k in SYNONYMS.get(want_label, [])):
            by_table[key]["want_cols"].append(c)
        if any(k in c.lower() for k in SYNONYMS["name"]):
            by_table[key]["name_cols"].append(c)
        if any(tt in typ for tt in TEXT_TYPES_HINT):
            by_table[key]["text_cols"].append(c)

    cands = []
    for (s, t), v in by_table.items():
        if v["want_cols"] and (v["name_cols"] or v["text_cols"]):
            cands.append({"schema": s, "table": t, **v})
    return cands

def make_like_param(x: str) -> str:
    return f"%{x}%"

def try_query(engine, schema: str, table: str, want_cols: List[str], name_cols: List[str], entity: str) -> pd.DataFrame:
    """
    Build a safe parameterized query using LIKE on name-like columns.
    Returns up to ROWS_PER_QUERY rows.
    """
    full = f"[{schema}].[{table}]"
    want_sel = ", ".join(f"[{wc}]" for wc in want_cols[:3])  # cap to keep narrow
    if not want_sel:
        want_sel = "*"

    # if name columns exist, search there; else fallback to all text columns
    where_parts = []
    params = {}
    if name_cols:
        for i, col in enumerate(name_cols[:4]):
            where_parts.append(f"[{col}] LIKE :p{i}")
            params[f"p{i}"] = make_like_param(entity)
    else:
        # shouldn't happen if we filtered cands, but guard anyway
        where_parts.append("1=1")

    sql = text(f"""
        SELECT TOP {ROWS_PER_QUERY}
            {want_sel},
            {", ".join(f"[{c}]" for c in name_cols[:3])}
        FROM {full}
        WHERE {" OR ".join(where_parts)}
    """)
    with engine.connect() as conn:
        try:
            return pd.read_sql(sql, conn, params=params)
        except Exception:
            # Some columns may be NVARCHAR(MAX) with non-like-able types; fallback to SELECT * TOP N no WHERE
            try:
                q = text(f"SELECT TOP {ROWS_PER_QUERY} {want_sel} FROM {full}")
                return pd.read_sql(q, conn)
            except Exception:
                return pd.DataFrame()

def answer_nlq(nlq: str) -> None:
    engine = make_engine()
    schema_rows = load_schema(engine)

    intent = guess_intent(nlq)
    entity = extract_entity(nlq)
    want = intent["want"]

    # Rank columns for the "want"
    want_cols_ranked = best_match_columns(schema_rows, [want])

    # Pick tables that have suitable columns
    candidates = build_candidates(schema_rows, want)

    # Light ranking: prefer tables where column name match is strong
    def score_table(cand):
        s, t = cand["schema"], cand["table"]
        col_hits = [sc for (cs, ct, cc, sc) in want_cols_ranked.get(want, []) if cs == s and ct == t]
        return max(col_hits) if col_hits else 0

    candidates.sort(key=score_table, reverse=True)
    candidates = candidates[:MAX_TABLES_TO_QUERY]

    print(f"\nQuestion: {nlq}")
    print(f"Detected intent: {want}  |  Entity: '{entity}'")
    if not candidates:
        print("No suitable tables found from schema hints.")
        return

    # Try querying each candidate until we get matches
    engine.dispose()
    engine = make_engine()
    results = []
    for cand in candidates:
        df = try_query(engine, cand["schema"], cand["table"], cand["want_cols"], cand["name_cols"], entity)
        if not df.empty:
            results.append((cand, df))

    if not results:
        print("No matching rows found (tried name-like search).")
        print("Tip: Try another spelling or add more context (e.g., 'employee phone of ...').")
        return

    # Present best result first
    for (cand, df) in results:
        print(f"\n=== {cand['schema']}.{cand['table']}  (showing up to {len(df)} rows) ===")
        # Bring likely columns to the front
        front_cols = cand["want_cols"][:2] + cand["name_cols"][:2]
        cols = list(dict.fromkeys(front_cols + list(df.columns)))
        print(df[cols].to_string(index=False))

def main():
    if len(sys.argv) > 1:
        nlq = " ".join(sys.argv[1:])
        answer_nlq(nlq)
        return

    print("Natural-language DB Q&A. Type a question, or 'quit'.")
    while True:
        try:
            q = input("\n> ").strip()
        except (EOFError, KeyboardInterrupt):
            break
        if not q or q.lower() in {"quit", "exit"}:
            break
        answer_nlq(q)

if __name__ == "__main__":
    main()
