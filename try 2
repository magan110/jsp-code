import os, re, json, requests
from typing import List, Dict, Tuple
import pandas as pd
import pyarrow as pa
import pyarrow.dataset as ds
from rapidfuzz import fuzz
from tqdm import tqdm

# ─── CONFIG ──────────────────────────────────────────────────────────────────
DATABASE      = "bwlive"  # matches your folder: db_export_bwlive
ROOT_OUT      = f"db_export_{DATABASE}"
CATALOG_JSON  = os.path.join(ROOT_OUT, "catalog.json")

# Ollama settings
OLLAMA_HOST   = os.environ.get("OLLAMA_HOST", "http://localhost:11434")
OLLAMA_MODEL  = os.environ.get("OLLAMA_MODEL", "llama3.1")  # change if you like
TEMPERATURE   = 0

# Retrieval limits
MAX_TABLES_TO_TRY       = 200
MAX_STRING_COLS_TO_READ = 50
ROWS_PER_TABLE_TO_SHOW  = 6        # rows passed to LLM as evidence
MAX_CONTEXT_CHARS       = 6000     # keep prompt small-ish
# ─────────────────────────────────────────────────────────────────────────────

# ---------- Catalog helpers ----------
def ensure_catalog() -> Dict:
    """Load catalog.json; if missing, build a minimal one by scanning parquet/."""
    if os.path.exists(CATALOG_JSON):
        with open(CATALOG_JSON, "r", encoding="utf-8") as f:
            return json.load(f)

    parquet_dir = os.path.join(ROOT_OUT, "parquet")
    if not os.path.isdir(parquet_dir):
        raise SystemExit(f"Parquet folder not found: {parquet_dir}")

    cat = {"database": DATABASE, "export_root": os.path.abspath(ROOT_OUT), "tables": {}}
    for schema in os.listdir(parquet_dir):
        sp = os.path.join(parquet_dir, schema)
        if not os.path.isdir(sp): continue
        for fn in os.listdir(sp):
            if fn.lower().endswith(".parquet"):
                table = fn[:-8]
                key = f"{schema}.{table}"
                cat["tables"][key] = {
                    "schema": schema, "table": table,
                    "parquet": os.path.join(sp, fn),
                    "row_count": None,
                }
    os.makedirs(ROOT_OUT, exist_ok=True)
    with open(CATALOG_JSON, "w", encoding="utf-8") as f:
        json.dump(cat, f, indent=2)
    return cat

# ---------- NLQ parsing (synonym-free) ----------
STOPWORDS = {
    "what","is","are","of","for","about","the","a","an","this","that","these","those",
    "show","give","get","find","list","name","names","code","codes","number","numbers",
    "top","first","last","all","and","or","with","without","please","pls","zone"
}
def extract_tokens(q: str) -> List[str]:
    # Prefer quoted chunk as main search
    m = re.search(r"[\"“”‘’']([^\"“”‘’']+)[\"“”‘’']", q)
    if m:
        raw = re.findall(r"[A-Za-z0-9@+._/-]+", m.group(1))
        return [t for t in raw if t]
    # Otherwise tokenize whole question
    raw = re.findall(r"[A-Za-z0-9@+._/-]+", q)
    toks = []
    for t in raw:
        tl = t.lower()
        if tl in STOPWORDS: continue
        if any(c.isdigit() for c in t) or len(t) >= 3:
            toks.append(t)
    if not toks and raw:
        toks = [raw[-1]]
    return toks

def is_list_tables(q: str) -> bool:
    L = q.lower().strip()
    return (
        bool(re.search(r"\b(list|show|name|names)\b", L) and re.search(r"\btables?\b", L))
        or L in {"tables","list tables","show tables","name of all tables","names of all tables"}
    )

def parse_top_n(q: str):
    m = re.search(r"\btop\s+(\d+)\s+([a-zA-Z0-9_.-]+)", q, flags=re.IGNORECASE)
    if m: return int(m.group(1)), m.group(2)
    return None

def best_table_match(catalog: Dict, frag: str) -> Tuple[str, Dict, int]:
    frag = frag.lower()
    best_key, best_meta, best_score = None, None, -1
    for key, meta in catalog["tables"].items():
        cands = [key.lower(), meta["table"].lower(), f"{meta['schema'].lower()}.{meta['table'].lower()}"]
        sc = max(fuzz.partial_ratio(frag, c) for c in cands)
        if sc > best_score:
            best_key, best_meta, best_score = key, meta, sc
    return best_key, best_meta, best_score

# ---------- Data readers ----------
def table_string_columns(dataset: ds.Dataset) -> List[str]:
    cols = []
    for f in dataset.schema:
        if pa.types.is_string(f.type) or pa.types.is_large_string(f.type) or pa.types.is_binary(f.type):
            cols.append(f.name)
    return cols[:MAX_STRING_COLS_TO_READ]

def search_table_tokens(parquet_path: str, tokens: List[str]) -> pd.DataFrame:
    dataset = ds.dataset(parquet_path, format="parquet")
    scols = table_string_columns(dataset)
    if not scols: return pd.DataFrame()
    tbl = dataset.to_table(columns=scols)
    df = tbl.to_pandas()
    if df.empty: return df

    # AND across tokens (each token must appear in some column)
    mask = pd.Series(True, index=df.index)
    for tok in tokens:
        m = pd.Series(False, index=df.index)
        for c in scols:
            try:
                m |= df[c].astype("string").str.contains(tok, case=False, na=False)
            except Exception:
                pass
        mask &= m
        if not mask.any(): return pd.DataFrame()
    return df[mask]

# ---------- Column ranking (pattern + stats) ----------
def looks_like_phone(s: pd.Series) -> float:
    if s.empty: return 0.0
    pat = re.compile(r"^\s*\+?\s*(?:\d[\s().-]?){7,15}\s*$")
    try:
        x = s.dropna().astype("string").str.fullmatch(pat)
        return float(x.sum()) / max(1, len(x))
    except Exception:
        return 0.0

def looks_like_email(s: pd.Series) -> float:
    if s.empty: return 0.0
    pat = re.compile(r"^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$")
    try:
        x = s.dropna().astype("string").str.fullmatch(pat)
        return float(x.sum()) / max(1, len(x))
    except Exception:
        return 0.0

def looks_like_idish(s: pd.Series) -> float:
    if s.empty: return 0.0
    try:
        ss = s.dropna().astype("string").str.strip()
        ss = ss[~ss.str.contains(r"@", na=False)]
        ss = ss[ss.str.len() <= 16]
        code_mask = ss.str.match(r"^[A-Za-z0-9._/-]+$")
        return float(code_mask.sum()) / max(1, len(s.dropna()))
    except Exception:
        return 0.0

def rank_columns(df: pd.DataFrame, question: str) -> List[str]:
    scores = []
    head = df.head(min(5000, len(df)))
    for col in df.columns:
        s = head[col]
        is_str = pd.api.types.is_string_dtype(s) or s.dtype == "object"
        ph = looks_like_phone(s) if is_str else 0.0
        em = looks_like_email(s) if is_str else 0.0
        idsc = looks_like_idish(s) if is_str else 0.0
        nunq = s.nunique(dropna=True); uniq_ratio = float(nunq) / max(1, len(head))
        sim = fuzz.partial_ratio(col.lower(), question.lower())
        score = 3.0*max(ph, em) + 1.3*idsc + 0.8*uniq_ratio + 0.02*sim
        scores.append((col, score))
    scores.sort(key=lambda x: x[1], reverse=True)
    top = [c for c, _ in scores[:6]]
    return top or list(df.columns[:3])

# ---------- Ollama ----------
def ask_ollama(prompt: str, model: str = OLLAMA_MODEL) -> str:
    url = f"{OLLAMA_HOST}/api/generate"
    payload = {"model": model, "prompt": prompt, "stream": False, "options": {"temperature": TEMPERATURE}}
    r = requests.post(url, json=payload, timeout=120)
    r.raise_for_status()
    txt = r.json().get("response", "").strip()
    # force one line
    txt = re.sub(r"\s+", " ", txt).strip()
    return txt

# ---------- Main answer flow ----------
def answer(q: str):
    catalog = ensure_catalog()

    # meta: list tables
    if is_list_tables(q):
        names = sorted([f"{v['schema']}.{v['table']}" for v in catalog["tables"].values()], key=str.lower)
        one_line = ", ".join(names)
        print(one_line); return

    # meta: top N table
    topn = parse_top_n(q)
    if topn:
        n, frag = topn
        key, meta, score = best_table_match(catalog, frag)
        if not meta or score < 40:
            print("Not found"); return
        try:
            df = pd.read_parquet(meta["parquet"]).head(n)
        except Exception:
            print("Not found"); return
        flat = df.to_string(index=False)
        prompt = (
            "You are a terse data assistant. In ONE short line, summarize the essence of these rows. "
            "Do not explain the table; extract the key item the user likely wants. If uncertain, say 'Not found'.\n\n"
            f"User question: {q}\n\nRows:\n{flat}\n\nOne-line answer:"
        )
        ans = ask_ollama(prompt)
        print(ans); return

    # generic: retrieve → compress → ask ollama
    tokens = extract_tokens(q)
    tables = list(catalog["tables"].items())[:MAX_TABLES_TO_TRY]

    contexts = []
    for _, meta in tqdm(tables, desc="Scanning tables", unit="table", dynamic_ncols=True):
        p = meta["parquet"]
        if not os.path.exists(p): continue
        try:
            hits = search_table_tokens(p, tokens)
        except Exception:
            continue
        if hits.empty: continue

        cols = rank_columns(hits, q)
        slim = hits[cols].head(ROWS_PER_TABLE_TO_SHOW)
        ctx = f"Table {meta['schema']}.{meta['table']}:\n" + slim.to_string(index=False)
        contexts.append(ctx)
        joined = "\n\n".join(contexts)
        if len(joined) >= MAX_CONTEXT_CHARS:
            break

    if not contexts:
        print("Not found"); return

    prompt = (
        "Answer the user's question using ONLY the provided rows. Respond in ONE short line with just the value(s). "
        "If multiple candidates exist, pick the most plausible. If unknown, reply exactly 'Not found'. "
        "Avoid extra words, punctuation, or labels.\n\n"
        f"User question: {q}\n\nContext rows:\n{joined}\n\nOne-line answer:"
    )
    ans = ask_ollama(prompt)
    print(ans)

# ---------- CLI ----------
if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1:
        answer(" ".join(sys.argv[1:]))
    else:
        print('Ollama DB Q&A (one-line). Examples:')
        print('  python ask_ollama.py "phone number of \\"rajendra shikwal\\""')
        print('  python ask_ollama.py "customer code of PZ6115"')
        print('  python ask_ollama.py "top 5 adtAnnGifts"')
        print('  python ask_ollama.py "name of all tables"')
        while True:
            try:
                q = input("\n> ").strip()
            except (EOFError, KeyboardInterrupt):
                break
            if not q or q.lower() in {"exit", "quit"}:
                break
            answer(q)
