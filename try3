import os, json, re, glob, random, datetime
import duckdb
import pandas as pd
from transformers import T5Tokenizer, T5ForConditionalGeneration

# ---------- Paths & environment ----------
DB_DIR      = "../db_export_bwlive"
CAT         = os.path.join(DB_DIR, "catalog.json")
MODEL_BASE  = "models/nl2sql_tiny"
ENV_MODEL   = os.environ.get("AI_DB_AGENT_MODEL", "")
ENV_SPM     = os.environ.get("AI_DB_AGENT_SPM", "")
DEBUG       = os.environ.get("AI_DB_AGENT_DEBUG", "0") == "1"

# ---------- Small-talk heuristics ----------
GREET_WORDS = {"hi","hello","hey","yo","namaste","hola","sup","hii","hiii","hlo"}
THANK_WORDS = {"thanks","thank you","ty","thx","shukriya","dhanyavaad"}
BYE_WORDS   = {"bye","goodbye","see ya","see you","tata"}
HELP_WORDS  = {"help","commands","examples","how to","what can you do"}
JOKE_WORDS  = {"joke","funny","make me laugh"}

# Words we don't want to search for as entity tokens
STOPWORDS = {
    "what","is","are","of","for","about","the","a","an","this","that","these","those",
    "show","give","get","find","list","name","names","code","codes","number","numbers",
    "top","first","last","all","and","or","with","without","please","pls","zone",
}

# Column-name cues
PHONE_COL_RE = re.compile(r"(mob|phone|phon|tel|contact|cell)", re.I)
EMAIL_COL_RE = re.compile(r"(email|e\-?mail|mailid|mail_id|mail)", re.I)

# ---------- Utils ----------
def _norm_path(p: str) -> str:
    return p.replace("\\", "/")

def _sql_escape_like(s: str) -> str:
    return (s or "").replace("'", "''")

def _has_model_files(d: str) -> bool:
    pats = [
        "pytorch_model.bin", "model.safetensors",
        "pytorch_model-*.bin", "model-*.safetensors",
        "pytorch_model.bin.index.json", "model.safetensors.index.json",
    ]
    return any(glob.glob(os.path.join(d, p)) for p in pats)

def _latest_checkpoint(base: str) -> str:
    if ENV_MODEL:
        use = os.path.abspath(ENV_MODEL)
        if not os.path.isdir(use): raise FileNotFoundError(f"AI_DB_AGENT_MODEL not a folder: {use}")
        if not _has_model_files(use): raise FileNotFoundError(f"No model files in {use}")
        return use
    if not os.path.isdir(base): raise FileNotFoundError(f"Model folder not found: {base}")
    cands = []
    for name in os.listdir(base):
        full = os.path.join(base, name)
        if os.path.isdir(full) and name.startswith("checkpoint-") and _has_model_files(full):
            try: cands.append((int(name.split("-")[-1]), full))
            except: pass
    if cands:
        cands.sort(key=lambda x: x[0])
        return cands[-1][1]
    if _has_model_files(base): return base
    raise FileNotFoundError(f"No usable model in {base}. Put weights in base or in checkpoint-* subfolders.")

def _find_sp_model(model_dir: str) -> str:
    if ENV_SPM and os.path.isfile(ENV_SPM):
        return os.path.abspath(ENV_SPM)
    for name in ("spiece.model","spm.model","sentencepiece.model","tokenizer.model"):
        p = os.path.join(model_dir, name)
        if os.path.isfile(p): return os.path.abspath(p)
    here = os.path.dirname(os.path.abspath(__file__))
    for name in ("spm.model","spiece.model","sentencepiece.model"):
        p = os.path.join(here, "data", name)
        if os.path.isfile(p): return os.path.abspath(p)
    raise FileNotFoundError(
        "SentencePiece .model not found. Copy data\\spm.model into the chosen checkpoint as spiece.model, "
        "or set AI_DB_AGENT_SPM to its full path."
    )

def _wanted_field(q: str):
    L = q.lower()
    if re.search(r"\b(email|e\-?mail)\b", L): return "email"
    if re.search(r"\b(mobile|phone|contact|tel|cell)\b", L): return "phone"
    return None

def _extract_name_hint(q: str):
    # Prefer quoted phrase as the entity name
    m = re.search(r"[\"‚Äú‚Äù'`](.+?)[\"‚Äú‚Äù'`]", q)
    if m:
        return m.group(1).strip()
    # Else, remove common words and keep a compact join as hint
    toks = _tokens_from_question(q)
    if not toks:
        return ""
    return " ".join(toks[:3])

def _tokens_from_question(q: str):
    m = re.search(r"[\"‚Äú‚Äù'`](.+?)[\"‚Äú‚Äù'`]", q)
    raw = re.findall(r"[A-Za-z0-9@+._/-]+", m.group(1) if m else q)
    toks = []
    for t in raw:
        tl = t.lower()
        if tl in STOPWORDS: continue
        if any(c.isdigit() for c in t) or len(t) >= 3:
            toks.append(t)
    if not toks and raw:
        toks = [max(raw, key=len)]
    return toks[:6]

def _looks_like_phone(s: pd.Series) -> float:
    if s is None or s.empty: return 0.0
    pat = re.compile(r"^\s*\+?\s*(?:\d[\s().-]?){7,15}\s*$")
    try:
        vals = s.dropna().astype(str)
        return float(vals.str.fullmatch(pat, na=False).sum()) / max(1, len(vals))
    except Exception:
        return 0.0

def _looks_like_email(s: pd.Series) -> float:
    if s is None or s.empty: return 0.0
    pat = re.compile(r"^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$")
    try:
        vals = s.dropna().astype(str)
        return float(vals.str.fullmatch(pat, na=False).sum()) / max(1, len(vals))
    except Exception:
        return 0.0

# ---------- Chat layer ----------
def is_probably_db_query(q: str) -> bool:
    L = q.lower()
    # strong DB cues
    cues = [
        r"\b(phone|mobile|contact|tel|email|e\-?mail)\b",
        r"\b(code|customer|cust|retail|retl|party|employee|emp|sap|invoice|docu|pin|pincode)\b",
        r"\b(list|show|top|count|where|select|table|rows?)\b",
        r"[A-Za-z]{2,}\d{2,}",  # id-ish like PZ6115, 4101P158
    ]
    return any(re.search(x, L) for x in cues)

def small_talk(q: str) -> str:
    L = q.strip().lower()
    words = set(re.findall(r"[a-z]+", L))

    if words & GREET_WORDS:
        return random.choice([
            "hey! how can i help?",
            "hello! ask me anything about your data‚Äîor just chat üôÇ",
            "hi! need a phone/email/code or some quick info?"
        ])
    if words & THANK_WORDS:
        return random.choice([
            "anytime!",
            "you‚Äôre welcome ‚ú®",
            "glad to help."
        ])
    if words & BYE_WORDS:
        return random.choice([
            "bye! have a good one üëã",
            "see you later!",
            "catch you soon!"
        ])
    if any(x in L for x in HELP_WORDS):
        return (
            "i‚Äôm your data assistant + chat buddy. try:\n"
            "‚Ä¢ phone number of \"rajendra shikwal\"\n"
            "‚Ä¢ email of PZ6115\n"
            "‚Ä¢ top 5 adtAnnGifts\n"
            "‚Ä¢ name of all tables\n"
            "you can also just chat: ‚Äútell me a joke‚Äù, ‚Äúwhat can you do‚Äù, etc."
        )
    if "time" in L or "date" in L or "today" in L:
        now = datetime.datetime.now()
        return f"it‚Äôs {now.strftime('%Y-%m-%d %H:%M:%S')} on your machine."

    if any(x in L for x in JOKE_WORDS):
        return random.choice([
            "why did the database admin break up with sql? too many joins. üòÖ",
            "i told my boss i know sql. they said: prove it. i replied: SELECT * FROM compliments;",
        ])

    # generic fallback chat
    return random.choice([
        "got it‚Äîask me anything about your database, or say 'help' for examples.",
        "i‚Äôm here. what do you want to find?",
        "cool. tell me who/what you‚Äôre looking for and i‚Äôll fetch it."
    ])

# ---------- Agent ----------
class DBAgent:
    def __init__(self):
        with open(CAT, "r", encoding="utf-8") as f:
            self.cat = json.load(f)

        self.model_dir = _latest_checkpoint(MODEL_BASE)
        spm_path = _find_sp_model(self.model_dir)
        print(f"[db-agent] model_dir: {self.model_dir}")
        print(f"[db-agent] spm:       {spm_path}")

        # tokenizer & model
        self.tok = T5Tokenizer(vocab_file=str(spm_path), legacy=True)
        if self.tok.pad_token is None: self.tok.add_special_tokens({"pad_token": "<pad>"})
        if self.tok.eos_token is None: self.tok.add_special_tokens({"eos_token": "</s>"})
        if self.tok.unk_token is None: self.tok.add_special_tokens({"unk_token": "<unk>"})
        if self.tok.bos_token is None: self.tok.add_special_tokens({"bos_token": "<s>"})
        self.model = T5ForConditionalGeneration.from_pretrained(self.model_dir)

        # DuckDB
        self.con = duckdb.connect(database=":memory:")
        self.con.execute("PRAGMA threads=4;")

    # ---------- NL‚ÜíSQL ----------
    def _gen_sql(self, question: str) -> str:
        ids = self.tok(question, return_tensors="pt", truncation=True, max_length=128)
        out = self.model.generate(**ids, max_length=128, num_beams=4, do_sample=False)
        sql = self.tok.decode(out[0], skip_special_tokens=True).strip().rstrip(";")
        if DEBUG: print(f"[db-agent] gen SQL: {sql}")
        return sql

    def _map_tables_to_parquet(self, sql: str) -> str:
        for key, meta in self.cat["tables"].items():
            path = _sql_escape_like(_norm_path(meta["parquet"]))
            pattern = rf'(?i)(?:["`])?{re.escape(key)}(?:["`])?'
            sql = re.sub(pattern, f"parquet('{path}')", sql)
        return sql

    def _tables(self):
        return sorted([f"{v['schema']}.{v['table']}" for v in self.cat["tables"].values()], key=str.lower)

    def _best_table(self, frag: str):
        frag = frag.lower()
        best, best_score = None, -1
        for key, meta in self.cat["tables"].items():
            cand2 = meta["table"].lower()
            score = max(int(frag in key.lower())*3, int(frag in cand2)*3, len(os.path.commonprefix([frag, cand2])))
            if score > best_score:
                best_score = score
                best = (key, meta)
        return best

    # ---------- Main chatbot entry ----------
    def ask(self, q: str) -> str:
        # If it doesn‚Äôt look like a DB query, do small talk
        if not is_probably_db_query(q):
            return small_talk(q)

        L = q.lower().strip()

        # quick control queries
        if (("list" in L or "show" in L or "name" in L) and "table" in L) or L in {"tables","list tables","show tables"}:
            return "here are your tables:\n- " + "\n- ".join(self._tables())

        m = re.search(r"top\s+(\d+)\s+([A-Za-z0-9_.-]+)", L)
        if m:
            n = int(m.group(1)); frag = m.group(2)
            best = self._best_table(frag)
            if not best: return "i couldn‚Äôt find a table matching that."
            _, meta = best
            p = _norm_path(meta["parquet"])
            try:
                df = self.con.execute(f"SELECT * FROM parquet('{_sql_escape_like(p)}') LIMIT {n}").fetchdf()
                return "here you go:\n" + (df.to_string(index=False) if not df.empty else "(no rows)")
            except Exception:
                return "sorry, i couldn‚Äôt read that table."

        # NL‚ÜíSQL path first
        sql = self._gen_sql(q)
        if re.match(r"^\s*select\b", sql, flags=re.IGNORECASE):
            try:
                sql2 = self._map_tables_to_parquet(sql)
                if DEBUG: print(f"[db-agent] remapped SQL: {sql2}")
                df = self.con.execute(sql2).fetchdf()
                if df.empty:
                    return self._fallback_natural(q, not_found=True)
                return self._format_db_answer(q, df)
            except Exception as e:
                if DEBUG: print(f"[db-agent] SQL error: {e}")
                # fall through to robust lexical fallback

        # robust fallback
        return self._fallback_natural(q)

    # ---------- Smarter fallback + natural phrasing ----------
    def _fallback_natural(self, q: str, not_found: bool = False) -> str:
        want = _wanted_field(q)    # 'phone'/'email'/None
        toks  = _tokens_from_question(q)
        if DEBUG: print(f"[db-agent] want={want} tokens={toks}")

        # Try tokens (AND, then OR)
        for mode in ("AND","OR"):
            df, meta = self._search_for_tokens_df(toks, mode=mode)
            if df is not None and not df.empty:
                if want:
                    vals = self._extract_wanted_values(df, want, k=5)
                    if vals:
                        name_hint = _extract_name_hint(q)
                        pretty = ", ".join(vals)
                        if want == "phone":
                            return f"phone for {name_hint or 'the match'}: {pretty}"
                        else:
                            return f"email for {name_hint or 'the match'}: {pretty}"
                # else show a compact snippet
                return f"i found matches in {meta['schema']}.{meta['table']}:\n" + df.head(5).to_string(index=False)

        # If user asked only 'email' / 'phone' with no name, sample
        if want in {"email","phone"} and not toks:
            vals = self._sample_field_across_tables(want, k=8)
            if vals:
                pretty = ", ".join(vals)
                return f"here are some {want}s i can see: {pretty}"
            return "i couldn‚Äôt spot any right away; try adding a name in quotes, e.g. phone of \"rajendra shikwal\"."

        # Truly nothing
        if not_found:
            return "i couldn‚Äôt find that. try adding a bit more detail, e.g. full name in quotes."
        return "hmm, i didn‚Äôt get a match. can you add more detail, maybe the full name in quotes?"

    def _search_for_tokens_df(self, tokens, mode="AND"):
        if not tokens:
            return None, None
        for key, meta in list(self.cat["tables"].items())[:200]:
            p = _norm_path(meta["parquet"])
            try:
                probe = self.con.execute(f"SELECT * FROM parquet('{_sql_escape_like(p)}') LIMIT 200").fetchdf()
            except Exception as e:
                if DEBUG: print(f"[db-agent] probe error {key}: {e}")
                continue
            if probe.empty: continue

            cols = list(probe.columns)
            per_tok = []
            for t in tokens:
                t_esc = _sql_escape_like(t)
                ors = [f"CAST(\"{c}\" AS VARCHAR) ILIKE '%{t_esc}%'" for c in cols]
                per_tok.append("(" + " OR ".join(ors) + ")")
            where = (" AND ".join(per_tok)) if mode == "AND" else (" OR ".join(per_tok))
            q2 = f"SELECT * FROM parquet('{_sql_escape_like(p)}') WHERE {where} LIMIT 25"
            try:
                df = self.con.execute(q2).fetchdf()
            except Exception as e:
                if DEBUG: print(f"[db-agent] scan err on {key}: {e}")
                continue
            if not df.empty:
                return df, meta
        return None, None

    def _extract_wanted_values(self, df: pd.DataFrame, want: str, k=5):
        # Rank columns by name cues + value pattern, then return distinct values
        scores = []
        sample = df.head(200)
        for c in df.columns:
            s = sample[c]
            name_bonus = 0.0
            pat_frac = 0.0
            try:
                if want == "phone":
                    if PHONE_COL_RE.search(c): name_bonus += 0.6
                    pat_frac = _looks_like_phone(s)
                elif want == "email":
                    if EMAIL_COL_RE.search(c): name_bonus += 0.6
                    pat_frac = _looks_like_email(s)
            except Exception:
                pass
            score = name_bonus + pat_frac
            if score > 0.15:
                scores.append((c, score))
        scores.sort(key=lambda x: x[1], reverse=True)
        vals = []
        for c,_ in scores:
            series = df[c].dropna().astype(str)
            if want == "phone":
                series = series[series.str.match(r"^\s*\+?\s*(?:\d[\s().-]?){7,15}\s*$", na=False)]
            elif want == "email":
                series = series[series.str.match(r"^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$", na=False)]
            for v in series.unique():
                v = v.strip()
                if v and v not in vals:
                    vals.append(v)
                    if len(vals) >= k:
                        return vals
        return vals

    def _sample_field_across_tables(self, want: str, k=8):
        vals = []
        for key, meta in list(self.cat["tables"].items())[:200]:
            p = _norm_path(meta["parquet"])
            try:
                df = self.con.execute(f"SELECT * FROM parquet('{_sql_escape_like(p)}') LIMIT 500").fetchdf()
            except Exception:
                continue
            if df.empty: continue
            for v in self._extract_wanted_values(df, want, k=k):
                if v not in vals:
                    vals.append(v)
                    if len(vals) >= k:
                        return vals
        return vals

    # ---------- Pretty formatting for DB answers ----------
    def _format_db_answer(self, q: str, df: pd.DataFrame) -> str:
        want = _wanted_field(q)
        if df.shape == (1,1):
            val = str(df.iat[0,0]).strip()
            if want == "phone":
                return f"phone: {val}" if val else "i didn‚Äôt find a phone there."
            if want == "email":
                return f"email: {val}" if val else "i didn‚Äôt find an email there."
            return val or "no value found."
        # multi-column or multi-row
        if want in {"phone","email"}:
            vals = self._extract_wanted_values(df, want, k=5)
            if vals:
                name_hint = _extract_name_hint(q)
                pretty = ", ".join(vals)
                if want == "phone":
                    return f"phone for {name_hint or 'the match'}: {pretty}"
                else:
                    return f"email for {name_hint or 'the match'}: {pretty}"
        # fallback: show a compact table
        return "here‚Äôs what i found:\n" + df.head(5).to_string(index=False)

# ---------- CLI ----------
if __name__ == "__main__":
    bot = DBAgent()
    print("chat + db agent ready. try:\n- phone number of \"rajendra shikwal\"\n- email of PZ6115\n- name of all tables\n- hi / help / tell me a joke")
    while True:
        try:
            s = input("\n> ").strip()
        except (EOFError, KeyboardInterrupt):
            break
        if not s or s.lower() in {"exit","quit"}:
            break
        print(bot.ask(s))
